{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(url: str, min_duration: float = 1, max_duration: float = 60, \n",
    "                                start_datetime_col: str = 'tpep_pickup_datetime', end_datetime_col: str = 'tpep_dropoff_datetime'):\n",
    "    # Download the Parquet file using requests\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Load the Parquet file directly from the downloaded bytes into a pandas DataFrame\n",
    "    df = pd.read_parquet(BytesIO(response.content))\n",
    "    \n",
    "    # Check if the required columns exist in the dataframe\n",
    "    if start_datetime_col not in df.columns or end_datetime_col not in df.columns:\n",
    "        raise ValueError(f\"Columns {start_datetime_col} or {end_datetime_col} not found in the dataset.\")\n",
    "    \n",
    "    # Calculate the trip duration (time difference between pickup and dropoff)\n",
    "    df['duration'] = pd.to_datetime(df[end_datetime_col]) - pd.to_datetime(df[start_datetime_col])\n",
    "    \n",
    "    # Convert the duration to minutes\n",
    "    df['duration'] = df['duration'].apply(lambda td: td.total_seconds() / 60)\n",
    "    \n",
    "    # Filter the data to include only trips that have a duration between min_duration and max_duration (inclusive)\n",
    "    df_filtered = df[(df['duration'] >= min_duration) & (df['duration'] <= max_duration)]\n",
    "    \n",
    "    # Return the filtered DataFrame with the standard deviation row\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 01 :Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3009173 entries, 0 to 3066765\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      " 19  duration               float64       \n",
      "dtypes: datetime64[us](2), float64(13), int64(4), object(1)\n",
      "memory usage: 482.1+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# URL of the Parquet file\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "\n",
    "# Load the parquet file directly from the downloaded bytes into a pandas DataFrame\n",
    "df_train =preprocess_df(url)\n",
    "\n",
    "# Check the structure and size of the DataFrame\n",
    "df_train.info()  # Check column types and non-null counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2855951 entries, 0 to 2913954\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int32         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int32         \n",
      " 8   DOLocationID           int32         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  Airport_fee            float64       \n",
      " 19  duration               float64       \n",
      "dtypes: datetime64[us](2), float64(13), int32(3), int64(1), object(1)\n",
      "memory usage: 424.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet'\n",
    "\n",
    "\n",
    "df_val = preprocess_df(url)\n",
    "# Check the structure and size of the DataFrame\n",
    "df_val.info()  # Check column types and non-null counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question02: Computing duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of trip durations in January: 42.59 minutes\n"
     ]
    }
   ],
   "source": [
    "# Now you can manipulate the DataFrame as you did before\n",
    "# Calculate the duration (time difference between pickup and dropoff)\n",
    "df_train['duration'] = pd.to_datetime(df_train['tpep_dropoff_datetime']) - pd.to_datetime(df_train['tpep_pickup_datetime'])\n",
    "df_val['duration'] = pd.to_datetime(df_val['tpep_dropoff_datetime']) - pd.to_datetime(df_val['tpep_pickup_datetime'])\n",
    "\n",
    "# Now, apply the total_seconds() method and convert to minutes\n",
    "df_train['duration'] = df_train['duration'].apply(lambda td: td.total_seconds() / 60)\n",
    "# Now, apply the total_seconds() method and convert to minutes\n",
    "df_val['duration'] = df_val['duration'].apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "#df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "# Step 4: Calculate the standard deviation of trip durations in January\n",
    "duration_std_january =df_train['duration'].std()\n",
    "# Output the result\n",
    "print(f\"Standard deviation of trip durations in January: {duration_std_january:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question03: Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of records left after dropping outliers: 0.98\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_train[(df_train['duration'] >= 1) & (df_train['duration'] <= 60)]\n",
    "fraction_left = len(df_filtered) / len(df)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Fraction of records left after dropping outliers: {fraction_left:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quesiton 04: One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3009173"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "df_train['PULocationID'] = df_train['PULocationID'].astype(str)\n",
    "df_train['DOLocationID'] = df_train['DOLocationID'].astype(str)\n",
    "\n",
    "df_val['PULocationID'] = df_val['PULocationID'].astype(str)\n",
    "df_val['DOLocationID'] = df_val['DOLocationID'].astype(str)\n",
    "\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df_train[categorical] = df_train[categorical].astype(str)\n",
    "df_val[categorical] = df_val[categorical].astype(str)\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical ].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical ].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of the feature matrix is: (3009173, 515)\n"
     ]
    }
   ],
   "source": [
    "dim = X_train.shape\n",
    "print(f\"The dimensionality of the feature matrix is: {dim}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of the feature matrix is: (2855951, 515)\n"
     ]
    }
   ],
   "source": [
    "dim = X_val.shape\n",
    "print(f\"The dimensionality of the feature matrix is: {dim}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'PULocationID': '161', 'DOLocationID': '141'}, {'PULocationID': '43', 'DOLocationID': '237'}, {'PULocationID': '48', 'DOLocationID': '238'}, {'PULocationID': '138', 'DOLocationID': '7'}, {'PULocationID': '107', 'DOLocationID': '79'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_dicts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 43)\t1.0\n",
      "  (0, 325)\t1.0\n",
      "  (1, 148)\t1.0\n",
      "  (1, 456)\t1.0\n",
      "  (2, 149)\t1.0\n",
      "  (2, 461)\t1.0\n",
      "  (3, 227)\t1.0\n",
      "  (3, 299)\t1.0\n",
      "  (4, 237)\t1.0\n",
      "  (4, 266)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 05: Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.649261027879736"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred, squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 06: Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.811832719365095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
